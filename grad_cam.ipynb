{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962496c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import os\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "from pytorch_grad_cam import GradCAMPlusPlus \n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "import torch.nn.functional as F\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8702fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_LIST = [\n",
    "    \"tox_safeshroom_best.pth\",\n",
    "    \"tox_safeshroom_best_alpha2.0.pth\",\n",
    "    \"tox_safeshroom_best_alpha5.0.pth\",\n",
    "    \"tox_safeshroom_best_alpha10.0.pth\",\n",
    "    \"tox_only_best_acc_bestsweep2.pth\"\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b002feb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SafeShroomMTL(nn.Module):\n",
    "    def __init__(self, num_species):\n",
    "        super(SafeShroomMTL, self).__init__()\n",
    "        self.backbone = models.efficientnet_b3(weights='DEFAULT')\n",
    "        in_features = self.backbone.classifier[1].in_features\n",
    "        self.backbone.classifier = nn.Identity()\n",
    "        self.species_head = nn.Linear(in_features, num_species)\n",
    "        self.tox_head = nn.Sequential(\n",
    "            nn.Linear(in_features, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 1) \n",
    "        )\n",
    "    def forward(self, x):\n",
    "        f = self.backbone(x)\n",
    "        return self.species_head(f), self.tox_head(f)\n",
    "\n",
    "class SafeShroomToxOnly(nn.Module):\n",
    "    def __init__(self, dropout_rate=0.7): \n",
    "        super(SafeShroomToxOnly, self).__init__()\n",
    "        self.backbone = models.efficientnet_b3(weights='DEFAULT')\n",
    "        in_features = self.backbone.classifier[1].in_features\n",
    "        self.backbone.classifier = nn.Identity()\n",
    "        self.tox_head = nn.Sequential(\n",
    "            nn.Linear(in_features, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate), \n",
    "            nn.Linear(64, 1) \n",
    "        )\n",
    "    def forward(self, x):\n",
    "        f = self.backbone(x)\n",
    "        return self.tox_head(f)\n",
    "\n",
    "class ToxicityModelWrapper(nn.Module):\n",
    "    def __init__(self, model, is_mtl):\n",
    "        super(ToxicityModelWrapper, self).__init__()\n",
    "        self.model = model\n",
    "        self.is_mtl = is_mtl\n",
    "    def forward(self, x):\n",
    "        if self.is_mtl:\n",
    "            _, tox_out = self.model(x)\n",
    "        else:\n",
    "            tox_out = self.model(x)\n",
    "        return tox_out\n",
    "    \n",
    "def load_model(path, num_species,device):\n",
    "    checkpoint = torch.load(path, map_location=device)\n",
    "    try:\n",
    "        model = SafeShroomMTL(num_species=num_species)\n",
    "        model.load_state_dict(checkpoint)\n",
    "        return model, True \n",
    "    except RuntimeError:\n",
    "        pass \n",
    "    try:\n",
    "        model = SafeShroomToxOnly()\n",
    "        model.load_state_dict(checkpoint)\n",
    "        return model, False \n",
    "    except RuntimeError as e:\n",
    "        print(f\"Could not load model {path}. Unknown architecture.\")\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d60d46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For seen species from test dataset\n",
    "IMAGE_FOLDER = '../image/yolo8x_300*300'\n",
    "TRAIN_CSV = '../../final_train_80.csv'  \n",
    "TEST_CSV = './gold_standard_100.csv' \n",
    "BASE_OUTPUT_DIR = './gradcam_comparisons'\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "IMG_SIZE = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286e57f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For species that are not seen by model but similar to species in dataset\n",
    "IMAGE_FOLDER = '../image/similar_unseen_image'\n",
    "TRAIN_CSV = '../../final_train_80.csv'  \n",
    "TEST_CSV = '../image/similar_unseen_image/similar_unseen_meta.csv' \n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "IMG_SIZE = 300\n",
    "BASE_OUTPUT_DIR = './gradcam_comparisons_unseen_similar'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed16ff2-0765-4731-b90f-07741005d3c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_model(model_path, train_csv, test_csv, img_folder):\n",
    "    \n",
    "    # Output Setup\n",
    "    model_name = os.path.basename(model_path).replace('.pth', '')\n",
    "    output_dir = os.path.join(BASE_OUTPUT_DIR, model_name)\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    report_path = os.path.join(output_dir, \"accuracy_report_detailed.txt\")\n",
    "    print(f\"\\nProcessing Model: {model_name}\")\n",
    "\n",
    "    # Load Resources\n",
    "    train_df = pd.read_csv(train_csv)\n",
    "    num_species = len(train_df['class_id'].unique())\n",
    "\n",
    "    try:\n",
    "        model, is_mtl = load_model(model_path, num_species,DEVICE)\n",
    "        model = model.to(DEVICE)\n",
    "        model.eval()\n",
    "    except Exception:\n",
    "        return\n",
    "\n",
    "    # GradCAM Setup\n",
    "    wrapped_model = ToxicityModelWrapper(model, is_mtl)\n",
    "    target_layers = [model.backbone.features[-1]]\n",
    "    cam = GradCAMPlusPlus(model=wrapped_model, target_layers=target_layers)\n",
    "\n",
    "    stats = ((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(*stats)\n",
    "    ])\n",
    "\n",
    "    # Processing Loop\n",
    "    df = pd.read_csv(test_csv)\n",
    "    \n",
    "    correct_count = 0\n",
    "    total_count = 0\n",
    "    \n",
    "    # Storage for detailed list\n",
    "    species_details = defaultdict(list)\n",
    "    \n",
    "    # Storage for summary stats\n",
    "    species_stats = defaultdict(lambda: {'correct': 0, 'total': 0, 'type': '?'})\n",
    "\n",
    "    print(f\" Generating GradCAMs\")\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        species_name = row.get('species', row.get('text_label', f\"Class {row.get('class_id', '?')}\"))\n",
    "        filename = os.path.basename(row['image_path'])\n",
    "        full_image_path = os.path.join(img_folder, filename)\n",
    "        \n",
    "        if not os.path.exists(full_image_path):\n",
    "            continue\n",
    "        try:\n",
    "            img = Image.open(full_image_path).convert('RGB')\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        # Inference\n",
    "        img_resized = img.resize((IMG_SIZE, IMG_SIZE))\n",
    "        input_tensor = preprocess(img_resized).unsqueeze(0).to(DEVICE)\n",
    "        rgb_img = np.float32(img_resized) / 255.0\n",
    "\n",
    "        if is_mtl:\n",
    "            _, tox_logits = model(input_tensor)\n",
    "        else:\n",
    "            tox_logits = model(input_tensor)\n",
    "            \n",
    "        tox_prob = torch.sigmoid(tox_logits).item()\n",
    "        \n",
    "        # Prediction Logic\n",
    "        # > 0.5 = POISON, <= 0.5 = SAFE\n",
    "        pred_label_str = \"POISON\" if tox_prob > 0.5 else \"SAFE\"\n",
    "        true_label_str = \"POISON\" if int(row['poisonous']) == 1 else \"SAFE\"\n",
    "        \n",
    "        is_correct = (pred_label_str == true_label_str)\n",
    "        icon = \"✅\" if is_correct else \"❌\"\n",
    "\n",
    "        # Update Summary Stats\n",
    "        total_count += 1\n",
    "        species_stats[species_name]['total'] += 1\n",
    "        species_stats[species_name]['type'] = true_label_str\n",
    "        if is_correct:\n",
    "            correct_count += 1\n",
    "            species_stats[species_name]['correct'] += 1\n",
    "\n",
    "        # Store Details for the Report\n",
    "        species_details[species_name].append({\n",
    "            'filename': filename,\n",
    "            'true': true_label_str,\n",
    "            'pred': pred_label_str,\n",
    "            'prob': tox_prob * 100, \n",
    "            'icon': icon\n",
    "        })\n",
    "\n",
    "        # Generate GradCAM \n",
    "        targets = [ClassifierOutputTarget(0)]\n",
    "        grayscale_cam = cam(input_tensor=input_tensor, targets=targets)[0, :]\n",
    "        vis = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)\n",
    "        vis = cv2.cvtColor(vis, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Annotate Image\n",
    "        color = (0, 255, 0) if is_correct else (0, 0, 255)\n",
    "        cv2.putText(vis, f\"Sp: {species_name}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "        cv2.putText(vis, f\"True: {true_label_str}\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "        cv2.putText(vis, f\"Pred: {pred_label_str} ({tox_prob*100:.1f}%)\", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "\n",
    "        # Save Image\n",
    "        safe_sp = str(species_name).replace(\" \", \"_\").replace(\"/\", \"-\")\n",
    "        save_name = f\"{output_dir}/{safe_sp}_{idx}_{true_label_str}_vs_{pred_label_str}.jpg\"\n",
    "        cv2.imwrite(save_name, vis)\n",
    "\n",
    "    # Generate FINAL Report\n",
    "    overall_acc = (correct_count / total_count * 100) if total_count > 0 else 0\n",
    "    \n",
    "    print(f\" Saving Detailed Report to {report_path}\")\n",
    "\n",
    "    with open(report_path, \"w\") as f:\n",
    "        f.write(f\"Model: {model_name}\\n\")\n",
    "        f.write(f\"Evaluating on: {test_csv}\\n\")\n",
    "        f.write(\"=\"*60 + \"\\n\")\n",
    "        f.write(f\"OVERALL ACCURACY: {overall_acc:.2f}% ({correct_count}/{total_count})\\n\")\n",
    "        f.write(\"=\"*60 + \"\\n\\n\")\n",
    "\n",
    "        # SUMMARY TABLE \n",
    "        f.write(f\"{'SPECIES (TYPE)':<45} | {'ACCURACY':<10} | {'CORRECT/TOTAL'}\\n\")\n",
    "        f.write(\"-\" * 75 + \"\\n\")\n",
    "        for sp, data in sorted(species_stats.items()):\n",
    "            sp_acc = (data['correct'] / data['total'] * 100) if data['total'] > 0 else 0\n",
    "            merged_name = f\"{sp} ({data['type']})\" \n",
    "            f.write(f\"{merged_name:<45} | {sp_acc:<9.1f}% | {data['correct']}/{data['total']}\\n\")\n",
    "        \n",
    "        f.write(\"\\n\\n\")\n",
    "\n",
    "        #  Detail Breakdown\n",
    "        # Iterate through species\n",
    "        for sp in sorted(species_details.keys()):\n",
    "            f.write(\"=\"*50 + \"\\n\")\n",
    "            f.write(f\"SPECIES GROUP: {sp}\\n\")\n",
    "            f.write(\"=\"*50 + \"\\n\")\n",
    "            \n",
    "            # Get list of images for this species\n",
    "            items = species_details[sp]\n",
    "            \n",
    "            # Print each image row\n",
    "            for i, item in enumerate(items, 1):\n",
    "                line = (f\"  [{i}] {item['filename']}: \"\n",
    "                        f\"True={item['true']} | \"\n",
    "                        f\"Pred={item['pred']} ({item['prob']:.1f}%) {item['icon']}\")\n",
    "                \n",
    "                f.write(line + \"\\n\")\n",
    "                print(line)\n",
    "            f.write(\"\\n\") \n",
    "\n",
    "    print(f\"\\nDone. Check {report_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efebdd4-ab77-4130-9547-2f11b361ff1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    print(f\"Starting Comparison for {len(MODEL_LIST)} models...\")\n",
    "    for model_path in MODEL_LIST:\n",
    "        evaluate_model(model_path, TRAIN_CSV, TEST_CSV, IMAGE_FOLDER)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
